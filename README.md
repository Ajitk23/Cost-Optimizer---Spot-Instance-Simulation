# Cost Optimizer â€“ Spot Instance Simulation

## ğŸ“Œ Project Overview

This project is an **educational Databricks notebook** that **simulates and visualizes cost savings** when running sample Spark jobs on **spot instances** versus **on-demand instances** in the cloud.

It helps **students, data engineers, and analysts** learn **how to reduce cloud computing costs** by understanding the pricing difference between spot and on-demand compute resources.

---

## ğŸ¯ Business Requirement

Cloud providers like AWS, Azure, and GCP offer **spot instances** (unused compute capacity sold at a discount) and **on-demand instances** (always available but more expensive).  
Running big data jobs on spot instances can save significant money â€” but comes with trade-offs like possible interruption.

This notebook shows how:
- The same Spark job (e.g., word count, data aggregation)
- Can cost much less if run on spot instances instead of on-demand
- By simulating job runtime, data size, and instance pricing
- And displaying the cost difference clearly with easy-to-read charts

---

## âš™ï¸ Tech Stack

- **Language:** Python (â‰¥3.8)
- **Processing:** PySpark
- **Platform:** Azure Databricks
- **Visualization:** matplotlib
- **Version Control:** Git + GitHub
- **Data:** Static CSV sample + JSON pricing file

---

## ğŸ“‚ Project Structure
cost-optimizer-simulation/
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ main_simulation_notebook.ipynb
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ spark_simulator.py
â”‚ â”œâ”€â”€ cost_calculator.py
â”‚ â”œâ”€â”€ visualization.py
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ pricing.json
â”‚ â””â”€â”€ sample_data.csv
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

